# ResNet

The goal of this project is to train a residual network (ResNet) with ~90% accuracy on the CIFAR-10 dataset using no more than 5 million trainable parameters. To do this, we performed a sweep of several hyperparameters including the number of residual blocks per layer, the stride, and the learning rate.

You can follow the parameter selection process in HyperparamSweep.ipynb, or jump straight to the final model in BestModel.ipynb.

Authors:
- Doug de Jesus <drd8913@nyu.edu>
- Tanaya Joshi <tj2181@nyu.edu>
- Thomas Maher <tm3566@nyu.edu>

This project was done for the class ECE-GY 7123 Deep Learning at NYU Tandon, taught by professors Chinmay Hegde and Arsalan Mosenia.
